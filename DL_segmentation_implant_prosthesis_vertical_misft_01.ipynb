{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has been compiled and utilized for training and testing of dental implant radiographic image processing\n",
    "# U-Net segmentation of vertical misfit of implant prosthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from pathlib import Path\n",
    "import re\n",
    "from skimage import measure\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "import matplotlib as mpl\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \".segmentation/data/images/IMAGES\"\n",
    "masks_path = \".segmentation/data/masks/MASKS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 5\n",
    "classes = {'bg':0, 'fixture': 1,  'abutment': 2,  'crown': 3, 'gap': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    x = np.array(x, dtype='float64')\n",
    "    x -= np.min(x)\n",
    "    x /= np.percentile(x, 98)\n",
    "    x[x > 1] = 1\n",
    "    return x\n",
    "\n",
    "def preprocessing(img):\n",
    "    image = np.array(img)   \n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image = np.zeros_like(image)\n",
    "    image[:,:,0] = gray\n",
    "    image[:,:,1] = gray\n",
    "    image[:,:,2] = gray\n",
    "    image = standardize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = []\n",
    "masks_paths = [] \n",
    "\n",
    "for imgname in os.listdir(images_path):\n",
    "  images_paths.append(os.path.join(images_path,imgname))\n",
    "\n",
    "for imgname in os.listdir(masks_path):\n",
    "  masks_paths.append(os.path.join(masks_path,imgname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths.sort()\n",
    "masks_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_paths[:5])\n",
    "print(masks_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_X = 256 \n",
    "SIZE_Y = 256\n",
    "n_classes = 5\n",
    "\n",
    "train_images = []\n",
    "train_masks = [] \n",
    "\n",
    "for imgpath in tqdm.tqdm(images_paths):\n",
    "  img = cv2.imread(imgpath)\n",
    "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "  img = preprocessing(img)               \n",
    "  train_images.append(img)\n",
    "\n",
    "\n",
    "for maskpath in tqdm.tqdm(masks_paths):\n",
    "  mask0 = cv2.imread(maskpath, 0)\n",
    "  mask1 = cv2.resize(mask0, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)\n",
    "  train_masks.append(mask1)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_masks = np.array(train_masks)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_masks, test_size = 0.15, shuffle=True, random_state = 1)\n",
    "print(\"Class values: \", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORM = mpl.colors.Normalize(vmin=0, vmax=4)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(1,4):\n",
    "    plt.subplot(2,3,i)\n",
    "    img = train_images[i]\n",
    "    plt.imshow(img)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "for i in range(4,7):\n",
    "    plt.subplot(2,3,i)\n",
    "    img = np.squeeze(train_masks[i-3])\n",
    "    plt.imshow(img, cmap='jet', norm=NORM)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels):\n",
    "    IMG_HEIGHT = X_train.shape[1]\n",
    "    IMG_WIDTH  = X_train.shape[2]\n",
    "    IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "    base_model = MobileNetV2(input_shape=[IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS], include_top=False, weights = 'imagenet')\n",
    "\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   \n",
    "        'block_3_expand_relu',   \n",
    "        'block_6_expand_relu',   \n",
    "        'block_13_expand_relu',  \n",
    "        'block_16_project',      \n",
    "    ]\n",
    "\n",
    "    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    down_stack = Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "\n",
    "    down_stack.trainable = False\n",
    "\n",
    "    up_stack = [\n",
    "        pix2pix.upsample(512, 3),  \n",
    "        pix2pix.upsample(256, 3),  \n",
    "        pix2pix.upsample(128, 3),  \n",
    "        pix2pix.upsample(64, 3),   \n",
    "    ]\n",
    "\n",
    "    inputs = Input(shape=[IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "\n",
    "    skips = down_stack(inputs)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    last = Conv2DTranspose(OUTPUT_CHANNELS, 5, strides=2, padding='same') \n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(base, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(epoch, dataset=None, num=50):\n",
    "  if dataset:\n",
    "    \n",
    "    for image, mask in dataset.take(num):\n",
    "        pred_mask = model.predict(image)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.subplot(231)\n",
    "        plt.title('Testing Image')\n",
    "        plt.imshow(image[0], cmap='gray')\n",
    "        plt.subplot(232)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.imshow(mask[0], cmap='jet')\n",
    "        plt.subplot(233)\n",
    "        plt.title('Prediction on test image')\n",
    "        plt.imshow(create_mask(pred_mask), cmap='jet')\n",
    "        \n",
    "        plt.savefig(f\"results/mask_{str(ii)}.png\")\n",
    "\n",
    "        plt.show()\n",
    "  else:\n",
    "      fig = plt.figure(figsize=(12, 12))\n",
    "      fig.suptitle(f\"\\n Epoch: {str(epoch)}\\n\", fontsize=16)\n",
    "\n",
    "      plt.subplot(331)\n",
    "      plt.title('Testing Image')\n",
    "      plt.imshow(train_images[num], cmap='gray')\n",
    "      plt.subplot(332)\n",
    "      plt.title('Ground Truth')\n",
    "      plt.imshow(train_masks[num], cmap='jet')\n",
    "      plt.subplot(333)\n",
    "      plt.title('Prediction on test image')\n",
    "      plt.imshow(create_mask(model.predict(train_images[num][tf.newaxis, ...]))[:,:,0], cmap='jet')\n",
    "\n",
    "      plt.subplot(334)\n",
    "      plt.imshow(train_images[num+16], cmap='gray')\n",
    "      plt.subplot(335)\n",
    "      plt.imshow(train_masks[num+16], cmap='jet')\n",
    "      plt.subplot(336)\n",
    "      plt.imshow(create_mask(model.predict(train_images[num+16][tf.newaxis, ...]))[:,:,0], cmap='jet')\n",
    "      plt.subplot(337)\n",
    "      plt.imshow(train_images[num+14], cmap='gray')\n",
    "      plt.subplot(338)\n",
    "      plt.imshow(train_masks[num+14], cmap='jet')\n",
    "      plt.subplot(339)\n",
    "      plt.imshow(create_mask(model.predict(train_images[num+14][tf.newaxis, ...]))[:,:,0], cmap='jet')\n",
    "\n",
    "      plt.savefig(f\"results/mask_{str(num+100)}_{str(epoch)}.png\")\n",
    "\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(OUTPUT_CHANNELS)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])   # \n",
    "              \n",
    "              metrics=[tf.keras.metrics.MeanIoU(num_classes=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "VAL_SUBSPLITS = 5\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_STEPS = len(X_val)//BATCH_SIZE//VAL_SUBSPLITS\n",
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "sample_image = train_images[0]\n",
    "sample_mask = train_masks[0]\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        show_predictions(epoch)\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "\n",
    "model_history = model.fit(X_train, y_train, epochs=EPOCHS,\n",
    "                           batch_size = BATCH_SIZE, \n",
    "                          verbose=1, \n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=(X_val, y_val),\n",
    "                          callbacks=[DisplayCallback()]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/vertical_misfit5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./models/vertical_misfit5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./data/test_images\" \n",
    "\n",
    "test_paths = [] \n",
    "\n",
    "for imgname in os.listdir(test_path):\n",
    "  test_paths.append(os.path.join(test_path,imgname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./data/test_images\" \n",
    "timgnum = 0\n",
    "img_num = int(test_paths[timgnum].split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "img = cv2.imread(test_paths[timgnum])\n",
    "img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "img = preprocessing(img)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "pred = np.array(create_mask(model.predict(img[tf.newaxis, ...])))\n",
    "plt.imshow(np.squeeze(pred))\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(train_masks[img_num-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_history.history\n",
    "acc=history_1['accuracy']\n",
    "val_acc = history_1['val_accuracy']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc[:150], '-', label='Training')\n",
    "plt.plot(val_acc[:150], '--', label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU = Intersection over union\n",
    "m = tf.keras.metrics.MeanIoU(num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef1(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    #print(tf.reduce_sum(y_true_f).numpy(), tf.reduce_sum(y_pred_f).numpy())\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=5\n",
    "dfs = {}\n",
    "for i in range(n_classes):\n",
    "  dfs[i]=[]\n",
    "\n",
    "for test_img_number in range(len(test_paths)):\n",
    "\n",
    "  test_img = test_images[test_img_number]\n",
    "  img_mask = test_masks[test_img_number]\n",
    "\n",
    "  predicted_img = np.squeeze(create_mask(model.predict(test_images[test_img_number][tf.newaxis, ...])).numpy())\n",
    "\n",
    "  img_mask_exp = np.zeros((SIZE_X, SIZE_Y, n_classes))\n",
    "  img_pred_exp = np.zeros((SIZE_X, SIZE_Y, n_classes))\n",
    "  for i in range(n_classes):\n",
    "    #print(test_img_number, i)\n",
    "    img_mask_exp[:,:,i][img_mask==i]=1\n",
    "    img_pred_exp[:,:,i][predicted_img==i]=1\n",
    "    df = dice_coef1(img_mask_exp[:,:,i], img_pred_exp[:,:,i]).numpy()\n",
    "    dfs[i].append(df)\n",
    "  \n",
    "dfss = []\n",
    "for i in range(n_classes):\n",
    "  avg = sum(dfs[i]) / len(dfs[i])\n",
    "  print(f\"Dice score of {str(i)}: {str(avg)}\")\n",
    "  dfss.append(avg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
